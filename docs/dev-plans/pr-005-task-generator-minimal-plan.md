# PR-005 — Task Generator (Minimal)

## References
- Operational MVP Spec: `docs/dev-plans/operational-mcp-integration-spec.md` [spec:OPS-MVP]
- PR-002: `docs/dev-plans/pr-002-provider-abstraction-and-config-hardening-plan.md` (provider abstraction, config hardening)
- PR-003: `docs/dev-plans/pr-003-context-service-skeleton-plan.md` (context service, read-only adapters)

## Summary & Scope
- Objective: Introduce a minimal, deterministic `TaskGeneratorTool` and `POST /ai/generate-tasks` endpoint that produces a small list of suggested tasks for a given prompt and optional project context.
- In-scope:
  - `TaskGeneratorTool` that orchestrates LLM call via provider factory (PR-002) and consumes read-only context (PR-003)
  - HTTP endpoint `POST /ai/generate-tasks` (validation, DTOs, error mapping)
  - Prompt template with strict output schema and guardrails
  - Validation to return between 3 and 12 tasks; reject/repair otherwise
  - Unit tests for tool and controller; contract tests for parsing/validation
- Out of scope:
  - Persistence or creation of tasks
  - Dependencies/links generation
  - Multi-turn or streaming UX

## Assumptions & Constraints
- Uses provider abstraction and config validation from PR-002 (Mistral default, OpenAI optional)
- Uses `ContextService` from PR-003 for optional project context (read-only)
- Strict output schema: no IDs generated by LLM; only titles and optional descriptions/priority
- Throughput constraints: synchronous single-shot call with timeout bound by provider

## Decisions (Locked for MVP)
- Response size: 3–12 tasks inclusive; outside range triggers repair or returns 400 with actionable message
- No hallucinated IDs allowed; server constructs ephemeral client IDs when needed
- Output fields: `title` (required), `description` (optional, short), `priority` (`LOW|MEDIUM|HIGH`, optional)
- English default; locale may be passed but prompt remains English for determinism

## API/Types
```ts
// Request DTO
export interface GenerateTasksRequestDto {
  prompt: string; // user intent
  projectId?: string; // optional to ground suggestions
  locale?: string; // optional, default 'en'
}

// Response DTO
export interface GeneratedTaskDto {
  title: string;
  description?: string;
  priority?: 'LOW' | 'MEDIUM' | 'HIGH';
}

export interface GenerateTasksResponseDto {
  tasks: ReadonlyArray<GeneratedTaskDto>; // length 3..12
  meta: {
    model: string;
    provider: string;
    tokensEstimated?: number;
    degraded: boolean; // true if context missing or truncated
  };
}
```

## Endpoint
- Route: `POST /ai/generate-tasks`
- Controller: `AiController`
- Service: `AiService` delegates to `TaskGeneratorTool`
- Validation: class-validator on request DTO; response typed

## Implementation Plan

### 1) Contracts & Validation
- [ ] Add DTOs under `src/ai/dto/generate-tasks.dto.ts` (request/response)
- [ ] Add zod or custom runtime validation for LLM output structure (array of 3–12 tasks)
- [ ] Enforce `priority` union; coerce unknown values to undefined

### 2) Tool Implementation
- [ ] Create `src/ai/tools/task-generator.tool.ts`
  - [ ] Build prompt template with few-shot examples and explicit JSON schema
  - [ ] Call provider via PR-002 factory with timeout
  - [ ] Parse and validate JSON; apply range enforcement and sanitization
  - [ ] Set `degraded` when project context fetch fails or is empty while requested

### 3) Context Integration (Read-Only)
- [ ] If `projectId` provided, call `ContextService.getProject` and `getTasks` (capped) for grounding
- [ ] Include only minimal fields in prompt (project name, top priorities inferred by simple heuristic)
- [ ] Never pass PII or long descriptions to the provider

### 4) HTTP Wiring
- [ ] Add controller route in `src/ai/ai.controller.ts` with request/response types
- [ ] Extend `AiService` with `generateTasks` delegating to tool
- [ ] Map provider errors to internal error codes (timeout/auth/bad-request/unavailable)

### 5) Observability & Limits
- [ ] Trace span `ai.taskgen.call` with tags `provider`, `model`, `projectId`, `degraded`
- [ ] Metrics: `ai.taskgen.request`, `ai.taskgen.error`, `ai.taskgen.latency`
- [ ] Config: `LLM_TASKGEN_TIMEOUT_MS` defaulting to provider timeout if unset

### 6) Tests
- [ ] Unit tests for tool: happy path (3–12 tasks), range too small/large (repair/fail), malformed JSON
- [ ] Unit tests for controller: validation errors, provider timeouts, error mapping
- [ ] Unit tests for context degraded path when `projectId` not found

### 7) Docs & Runbook
- [ ] Update `docs/dev-plans` with usage examples (curl) and DTO shapes
- [ ] Document configuration flags and failure modes

## Prompt Shape (Draft)
```md
System: You are a precise task generator. Output ONLY valid JSON matching the provided schema. No IDs.

User: Generate 3–12 actionable tasks from the intent and optional context.

Schema:
{
  "tasks": [
    {
      "title": string,
      "description"?: string,
      "priority"?: "LOW" | "MEDIUM" | "HIGH"
    }
  ]
}

Rules:
- No additional fields.
- Titles ≤ 80 chars. Descriptions ≤ 240 chars.
- No IDs. No markdown. JSON only.
```

## Acceptance Criteria
- [ ] `POST /ai/generate-tasks` returns 200 with 3–12 tasks for valid prompt
- [ ] No IDs are present in responses; fields limited to allowed keys
- [ ] Range enforcement guaranteed; malformed or out-of-range responses are repaired or rejected
- [ ] Degraded flag set when context is missing/unavailable while requested
- [ ] Timeouts and provider errors mapped to stable internal codes; logs redact prompts/responses in prod
- [ ] Unit tests cover the above paths

## Definition of Done
- [ ] DTOs defined and validated
- [ ] `TaskGeneratorTool` implemented and integrated
- [ ] Endpoint added with tests passing
- [ ] Observability added (traces, metrics)
- [ ] Documentation updated with examples and env config

## Risks & Mitigations
- Output drift: enforce JSON schema and length bounds; use few-shot examples
- Latency spikes: keep prompt short; set strict timeout; degrade gracefully without context
- Provider variability: pin model; keep temperature low; add minimal retries off-by-default

## Open Questions
- Should we provide a `maxTasks` hint in request, bounded by 12?
- Do we need locale-conditioned output now, or always return English for MVP?
- Any additional redaction needed for project names/titles before sending to provider?

## Changelog
- 2025-09-23: Initial PR-005 battle plan drafted per OPS-MVP.


